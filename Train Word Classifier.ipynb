***REMOVED***
 "cells": [
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 99,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 100,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "simple_sentences = np.load('generated_data/simple.npy')\n",
    "complex_sentences = np.load('generated_data/complex.npy')\n",
    "\n",
    "simple_outs = np.zeros(len(simple_sentences))\n",
    "complex_outs = np.zeros(len(complex_sentences)) + 1"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 101,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "# combine true and falses\n",
    "all_sentences = np.concatenate((simple_sentences, complex_sentences))\n",
    "all_outputs = np.concatenate((simple_outs, complex_outs))"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 102,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "random_iter = np.arange(len(all_sentences))\n",
    "np.random.shuffle(random_iter)\n",
    "all_sentences = all_sentences[random_iter]\n",
    "all_outputs = all_outputs[random_iter]"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 103,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_sentences, all_outputs, test_size=0.2)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 104,
   "metadata": ***REMOVED******REMOVED***,
   "outputs": [
    ***REMOVED***
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2714,) (10854,)\n"
     ]
    ***REMOVED***
   ],
   "source": [
    "print(X_test.shape, X_train.shape, )"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 105,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "max_wiki_length = 50\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_wiki_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_wiki_length)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 106,
   "metadata": ***REMOVED***
    "scrolled": true
   ***REMOVED***,
   "outputs": [
    ***REMOVED***
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 50, 32)            320000    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 549,201\n",
      "Trainable params: 549,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 10854 samples, validate on 2714 samples\n",
      "Epoch 1/1000\n",
      "10854/10854 [==============================] - 17s 2ms/step - loss: 0.6940 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.5037\n",
      "Epoch 2/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6935 - acc: 0.4991 - val_loss: 0.6935 - val_acc: 0.4915\n",
      "Epoch 3/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6933 - acc: 0.5100 - val_loss: 0.6936 - val_acc: 0.4889\n",
      "Epoch 4/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6934 - acc: 0.5005 - val_loss: 0.6929 - val_acc: 0.5011\n",
      "Epoch 5/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6933 - acc: 0.4959 - val_loss: 0.6930 - val_acc: 0.5177\n",
      "Epoch 6/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6933 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5029\n",
      "Epoch 7/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6932 - acc: 0.5043 - val_loss: 0.6975 - val_acc: 0.4480\n",
      "Epoch 8/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6933 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.4904\n",
      "Epoch 9/1000\n",
      "10854/10854 [==============================] - 15s 1ms/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6936 - val_acc: 0.4904\n",
      "Epoch 10/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6934 - acc: 0.5029 - val_loss: 0.6932 - val_acc: 0.4930\n",
      "Epoch 11/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6932 - acc: 0.5058 - val_loss: 0.6935 - val_acc: 0.4904\n",
      "Epoch 12/1000\n",
      "10854/10854 [==============================] - 11s 991us/step - loss: 0.6929 - acc: 0.5097 - val_loss: 0.6935 - val_acc: 0.4587\n",
      "Epoch 13/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6927 - acc: 0.5135 - val_loss: 0.6934 - val_acc: 0.4834\n",
      "Epoch 14/1000\n",
      "10854/10854 [==============================] - 11s 984us/step - loss: 0.6923 - acc: 0.5164 - val_loss: 0.7016 - val_acc: 0.3029\n",
      "Epoch 15/1000\n",
      "10854/10854 [==============================] - 10s 952us/step - loss: 0.6916 - acc: 0.5206 - val_loss: 0.7110 - val_acc: 0.2973\n",
      "Epoch 16/1000\n",
      "10854/10854 [==============================] - 10s 937us/step - loss: 0.6904 - acc: 0.5220 - val_loss: 0.7319 - val_acc: 0.2380\n",
      "Epoch 17/1000\n",
      "10854/10854 [==============================] - 10s 945us/step - loss: 0.6873 - acc: 0.5311 - val_loss: 0.7371 - val_acc: 0.2999\n",
      "Epoch 18/1000\n",
      "10854/10854 [==============================] - 10s 945us/step - loss: 0.6852 - acc: 0.5294 - val_loss: 0.8066 - val_acc: 0.2229\n",
      "Epoch 19/1000\n",
      "10854/10854 [==============================] - 10s 940us/step - loss: 0.6814 - acc: 0.5345 - val_loss: 0.7801 - val_acc: 0.2461\n",
      "Epoch 20/1000\n",
      "10854/10854 [==============================] - 10s 938us/step - loss: 0.6780 - acc: 0.5379 - val_loss: 0.7789 - val_acc: 0.2284\n",
      "Epoch 21/1000\n",
      "10854/10854 [==============================] - 11s 989us/step - loss: 0.6751 - acc: 0.5322 - val_loss: 0.8383 - val_acc: 0.1802\n",
      "Epoch 22/1000\n",
      "10854/10854 [==============================] - 11s 977us/step - loss: 0.6703 - acc: 0.5332 - val_loss: 0.9149 - val_acc: 0.1765\n",
      "Epoch 23/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6645 - acc: 0.5327 - val_loss: 1.0292 - val_acc: 0.1857\n",
      "Epoch 24/1000\n",
      "10854/10854 [==============================] - 10s 958us/step - loss: 0.6533 - acc: 0.5463 - val_loss: 1.4131 - val_acc: 0.1665\n",
      "Epoch 25/1000\n",
      "10854/10854 [==============================] - 11s 977us/step - loss: 0.6436 - acc: 0.5439 - val_loss: 1.5843 - val_acc: 0.1621\n",
      "Epoch 26/1000\n",
      "10854/10854 [==============================] - 10s 950us/step - loss: 0.6341 - acc: 0.5508 - val_loss: 1.8530 - val_acc: 0.1658\n",
      "Epoch 27/1000\n",
      "10854/10854 [==============================] - 10s 944us/step - loss: 0.6247 - acc: 0.5484 - val_loss: 2.0252 - val_acc: 0.1551\n",
      "Epoch 28/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.6188 - acc: 0.5523 - val_loss: 2.1826 - val_acc: 0.1743\n",
      "Epoch 29/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6119 - acc: 0.5504 - val_loss: 2.4598 - val_acc: 0.1606\n",
      "Epoch 30/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6079 - acc: 0.5488 - val_loss: 2.4181 - val_acc: 0.1444\n",
      "Epoch 31/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6052 - acc: 0.5453 - val_loss: 3.1072 - val_acc: 0.1507\n",
      "Epoch 32/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.6003 - acc: 0.5513 - val_loss: 3.1537 - val_acc: 0.1555\n",
      "Epoch 33/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5979 - acc: 0.5655 - val_loss: 2.8617 - val_acc: 0.1389\n",
      "Epoch 34/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5964 - acc: 0.5601 - val_loss: 2.7591 - val_acc: 0.1349\n",
      "Epoch 35/1000\n",
      "10854/10854 [==============================] - 11s 999us/step - loss: 0.5948 - acc: 0.5627 - val_loss: 3.4644 - val_acc: 0.1548\n",
      "Epoch 36/1000\n",
      "10854/10854 [==============================] - 11s 992us/step - loss: 0.5927 - acc: 0.5606 - val_loss: 3.6557 - val_acc: 0.1367\n",
      "Epoch 37/1000\n",
      "10854/10854 [==============================] - 11s 993us/step - loss: 0.5896 - acc: 0.5692 - val_loss: 3.9864 - val_acc: 0.1570\n",
      "Epoch 38/1000\n",
      "10854/10854 [==============================] - 10s 952us/step - loss: 0.5901 - acc: 0.5638 - val_loss: 3.6125 - val_acc: 0.1419\n",
      "Epoch 39/1000\n",
      "10854/10854 [==============================] - 10s 945us/step - loss: 0.5889 - acc: 0.5576 - val_loss: 3.7289 - val_acc: 0.1367\n",
      "Epoch 40/1000\n",
      "10854/10854 [==============================] - 11s 978us/step - loss: 0.5873 - acc: 0.5564 - val_loss: 3.9790 - val_acc: 0.1282\n",
      "Epoch 41/1000\n",
      "10854/10854 [==============================] - 10s 947us/step - loss: 0.5860 - acc: 0.5547 - val_loss: 4.1746 - val_acc: 0.1301\n",
      "Epoch 42/1000\n",
      "10854/10854 [==============================] - 10s 954us/step - loss: 0.5854 - acc: 0.5589 - val_loss: 3.5416 - val_acc: 0.1363\n",
      "Epoch 43/1000\n",
      "10854/10854 [==============================] - 10s 952us/step - loss: 0.5843 - acc: 0.5577 - val_loss: 4.0586 - val_acc: 0.1367\n",
      "Epoch 44/1000\n",
      "10854/10854 [==============================] - 10s 937us/step - loss: 0.5850 - acc: 0.5672 - val_loss: 3.6428 - val_acc: 0.1234\n",
      "Epoch 45/1000\n",
      "10854/10854 [==============================] - 10s 951us/step - loss: 0.5834 - acc: 0.5580 - val_loss: 3.9667 - val_acc: 0.1242\n",
      "Epoch 46/1000\n",
      "10854/10854 [==============================] - 10s 954us/step - loss: 0.5829 - acc: 0.5587 - val_loss: 4.6579 - val_acc: 0.1279\n",
      "Epoch 47/1000\n",
      "10854/10854 [==============================] - 10s 949us/step - loss: 0.5816 - acc: 0.5624 - val_loss: 4.7653 - val_acc: 0.1190\n",
      "Epoch 48/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5950 - acc: 0.5622 - val_loss: 3.8932 - val_acc: 0.1466\n",
      "Epoch 49/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5874 - acc: 0.5724 - val_loss: 4.0114 - val_acc: 0.1304\n",
      "Epoch 50/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5825 - acc: 0.5602 - val_loss: 3.8575 - val_acc: 0.1183\n",
      "Epoch 51/1000\n"
     ]
    ***REMOVED***,
    ***REMOVED***
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5797 - acc: 0.5626 - val_loss: 3.9575 - val_acc: 0.1201\n",
      "Epoch 52/1000\n",
      "10854/10854 [==============================] - 10s 957us/step - loss: 0.5792 - acc: 0.5593 - val_loss: 4.2006 - val_acc: 0.1286\n",
      "Epoch 53/1000\n",
      "10854/10854 [==============================] - 11s 991us/step - loss: 0.5793 - acc: 0.5691 - val_loss: 4.2929 - val_acc: 0.1275\n",
      "Epoch 54/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5788 - acc: 0.5630 - val_loss: 4.2420 - val_acc: 0.1183\n",
      "Epoch 55/1000\n",
      "10854/10854 [==============================] - 11s 980us/step - loss: 0.5772 - acc: 0.5773 - val_loss: 4.4586 - val_acc: 0.1227\n",
      "Epoch 56/1000\n",
      "10854/10854 [==============================] - 11s 978us/step - loss: 0.5776 - acc: 0.5674 - val_loss: 5.0687 - val_acc: 0.1268\n",
      "Epoch 57/1000\n",
      "10854/10854 [==============================] - 10s 960us/step - loss: 0.5776 - acc: 0.5671 - val_loss: 5.0487 - val_acc: 0.1242\n",
      "Epoch 58/1000\n",
      "10854/10854 [==============================] - 10s 957us/step - loss: 0.5782 - acc: 0.5626 - val_loss: 4.6537 - val_acc: 0.1190\n",
      "Epoch 59/1000\n",
      "10854/10854 [==============================] - 10s 951us/step - loss: 0.5781 - acc: 0.5727 - val_loss: 4.2102 - val_acc: 0.1197\n",
      "Epoch 60/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5803 - acc: 0.5716 - val_loss: 4.3346 - val_acc: 0.1249\n",
      "Epoch 61/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5782 - acc: 0.5711 - val_loss: 5.1691 - val_acc: 0.1190\n",
      "Epoch 62/1000\n",
      "10854/10854 [==============================] - 10s 960us/step - loss: 0.5788 - acc: 0.5637 - val_loss: 4.0067 - val_acc: 0.1382\n",
      "Epoch 63/1000\n",
      "10854/10854 [==============================] - 10s 944us/step - loss: 0.5777 - acc: 0.5837 - val_loss: 4.5683 - val_acc: 0.1352\n",
      "Epoch 64/1000\n",
      "10854/10854 [==============================] - 10s 934us/step - loss: 0.5770 - acc: 0.5689 - val_loss: 5.1820 - val_acc: 0.1433\n",
      "Epoch 65/1000\n",
      "10854/10854 [==============================] - 10s 929us/step - loss: 0.5773 - acc: 0.5670 - val_loss: 4.3638 - val_acc: 0.1197\n",
      "Epoch 66/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5754 - acc: 0.5718 - val_loss: 4.9411 - val_acc: 0.1275\n",
      "Epoch 67/1000\n",
      "10854/10854 [==============================] - 10s 941us/step - loss: 0.5768 - acc: 0.5782 - val_loss: 4.2062 - val_acc: 0.1245\n",
      "Epoch 68/1000\n",
      "10854/10854 [==============================] - 10s 966us/step - loss: 0.5766 - acc: 0.5774 - val_loss: 4.7422 - val_acc: 0.1220\n",
      "Epoch 69/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5765 - acc: 0.5763 - val_loss: 3.4024 - val_acc: 0.1201\n",
      "Epoch 70/1000\n",
      "10854/10854 [==============================] - 19s 2ms/step - loss: 0.5781 - acc: 0.5537 - val_loss: 4.6551 - val_acc: 0.1150\n",
      "Epoch 71/1000\n",
      "10854/10854 [==============================] - 18s 2ms/step - loss: 0.5749 - acc: 0.5681 - val_loss: 4.6500 - val_acc: 0.1212\n",
      "Epoch 72/1000\n",
      "10854/10854 [==============================] - 15s 1ms/step - loss: 0.5748 - acc: 0.5731 - val_loss: 4.9021 - val_acc: 0.1242\n",
      "Epoch 73/1000\n",
      "10854/10854 [==============================] - 18s 2ms/step - loss: 0.5746 - acc: 0.5653 - val_loss: 5.0443 - val_acc: 0.1153\n",
      "Epoch 74/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.5746 - acc: 0.5679 - val_loss: 5.4750 - val_acc: 0.1205\n",
      "Epoch 75/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5751 - acc: 0.5803 - val_loss: 4.9862 - val_acc: 0.1183\n",
      "Epoch 76/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5753 - acc: 0.5767 - val_loss: 4.9134 - val_acc: 0.1168\n",
      "Epoch 77/1000\n",
      "10854/10854 [==============================] - 11s 989us/step - loss: 0.5773 - acc: 0.5875 - val_loss: 4.1332 - val_acc: 0.1444\n",
      "Epoch 78/1000\n",
      "10854/10854 [==============================] - 10s 938us/step - loss: 0.5752 - acc: 0.5764 - val_loss: 4.7992 - val_acc: 0.1268\n",
      "Epoch 79/1000\n",
      "10854/10854 [==============================] - 10s 945us/step - loss: 0.5735 - acc: 0.5678 - val_loss: 5.5764 - val_acc: 0.1216\n",
      "Epoch 80/1000\n",
      "10854/10854 [==============================] - 10s 934us/step - loss: 0.5733 - acc: 0.5805 - val_loss: 5.2622 - val_acc: 0.1175\n",
      "Epoch 81/1000\n",
      "10854/10854 [==============================] - 11s 983us/step - loss: 0.5738 - acc: 0.5792 - val_loss: 5.0519 - val_acc: 0.1223\n",
      "Epoch 82/1000\n",
      "10854/10854 [==============================] - 10s 948us/step - loss: 0.5725 - acc: 0.5834 - val_loss: 5.2367 - val_acc: 0.1275\n",
      "Epoch 83/1000\n",
      "10854/10854 [==============================] - 10s 941us/step - loss: 0.5731 - acc: 0.5721 - val_loss: 5.7687 - val_acc: 0.1168\n",
      "Epoch 84/1000\n",
      "10854/10854 [==============================] - 11s 985us/step - loss: 0.5730 - acc: 0.5838 - val_loss: 5.0739 - val_acc: 0.1297\n",
      "Epoch 85/1000\n",
      "10854/10854 [==============================] - 11s 984us/step - loss: 0.5728 - acc: 0.5788 - val_loss: 6.0414 - val_acc: 0.1172\n",
      "Epoch 86/1000\n",
      "10854/10854 [==============================] - 10s 953us/step - loss: 0.5744 - acc: 0.5826 - val_loss: 5.5520 - val_acc: 0.1190\n",
      "Epoch 87/1000\n",
      "10854/10854 [==============================] - 10s 939us/step - loss: 0.5736 - acc: 0.5778 - val_loss: 4.8557 - val_acc: 0.1183\n",
      "Epoch 88/1000\n",
      "10854/10854 [==============================] - 10s 956us/step - loss: 0.5766 - acc: 0.5744 - val_loss: 6.6517 - val_acc: 0.1124\n",
      "Epoch 89/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5743 - acc: 0.5813 - val_loss: 7.8062 - val_acc: 0.1164\n",
      "Epoch 90/1000\n",
      "10854/10854 [==============================] - 10s 953us/step - loss: 0.5724 - acc: 0.5804 - val_loss: 5.7134 - val_acc: 0.1164\n",
      "Epoch 91/1000\n",
      "10854/10854 [==============================] - 11s 996us/step - loss: 0.5734 - acc: 0.5814 - val_loss: 4.8138 - val_acc: 0.1179\n",
      "Epoch 92/1000\n",
      "10854/10854 [==============================] - 10s 950us/step - loss: 0.5732 - acc: 0.5885 - val_loss: 4.6460 - val_acc: 0.1150\n",
      "Epoch 93/1000\n",
      "10854/10854 [==============================] - 11s 985us/step - loss: 0.5709 - acc: 0.5707 - val_loss: 5.3920 - val_acc: 0.1146\n",
      "Epoch 94/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5708 - acc: 0.5790 - val_loss: 6.5030 - val_acc: 0.1161\n",
      "Epoch 95/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5841 - acc: 0.5708 - val_loss: 1.4572 - val_acc: 0.2940\n",
      "Epoch 96/1000\n",
      "10854/10854 [==============================] - 10s 934us/step - loss: 0.6103 - acc: 0.5746 - val_loss: 3.0406 - val_acc: 0.1256\n",
      "Epoch 97/1000\n",
      "10854/10854 [==============================] - 10s 948us/step - loss: 0.5862 - acc: 0.5763 - val_loss: 4.1385 - val_acc: 0.1205\n",
      "Epoch 98/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5743 - acc: 0.5783 - val_loss: 5.0722 - val_acc: 0.1153\n",
      "Epoch 99/1000\n",
      "10854/10854 [==============================] - 10s 949us/step - loss: 0.5711 - acc: 0.5810 - val_loss: 5.5337 - val_acc: 0.1135\n",
      "Epoch 100/1000\n",
      "10854/10854 [==============================] - 10s 937us/step - loss: 0.5697 - acc: 0.5760 - val_loss: 5.5573 - val_acc: 0.1157\n",
      "Epoch 101/1000\n",
      "10854/10854 [==============================] - 10s 935us/step - loss: 0.5695 - acc: 0.5826 - val_loss: 5.4854 - val_acc: 0.1131\n",
      "Epoch 102/1000\n",
      "10854/10854 [==============================] - 10s 945us/step - loss: 0.5690 - acc: 0.5740 - val_loss: 6.2175 - val_acc: 0.1124\n",
      "Epoch 103/1000\n",
      "10854/10854 [==============================] - 10s 940us/step - loss: 0.5684 - acc: 0.5834 - val_loss: 6.1213 - val_acc: 0.1150\n",
      "Epoch 104/1000\n",
      "10854/10854 [==============================] - 10s 948us/step - loss: 0.5682 - acc: 0.5827 - val_loss: 5.5020 - val_acc: 0.1142\n",
      "Epoch 105/1000\n",
      "10854/10854 [==============================] - 10s 945us/step - loss: 0.5676 - acc: 0.5935 - val_loss: 5.5006 - val_acc: 0.1127\n",
      "Epoch 106/1000\n",
      "10854/10854 [==============================] - 11s 1ms/step - loss: 0.5671 - acc: 0.5837 - val_loss: 5.8277 - val_acc: 0.1186\n",
      "Epoch 107/1000\n",
      "10854/10854 [==============================] - 12s 1ms/step - loss: 0.5678 - acc: 0.5822 - val_loss: 5.5774 - val_acc: 0.1139\n",
      "Epoch 108/1000\n",
      "10854/10854 [==============================] - 11s 996us/step - loss: 0.5670 - acc: 0.5844 - val_loss: 6.3384 - val_acc: 0.1135\n"
     ]
    ***REMOVED***,
    ***REMOVED***
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "10854/10854 [==============================] - 11s 982us/step - loss: 0.5674 - acc: 0.5897 - val_loss: 6.6900 - val_acc: 0.1127\n",
      "Epoch 110/1000\n",
      "10854/10854 [==============================] - 11s 1000us/step - loss: 0.5697 - acc: 0.5825 - val_loss: 5.6366 - val_acc: 0.1186\n",
      "Epoch 111/1000\n",
      "10854/10854 [==============================] - 11s 973us/step - loss: 0.5713 - acc: 0.5842 - val_loss: 4.9994 - val_acc: 0.1124\n",
      "Epoch 112/1000\n",
      "10854/10854 [==============================] - 10s 940us/step - loss: 0.5678 - acc: 0.5812 - val_loss: 5.4621 - val_acc: 0.1197\n",
      "Epoch 113/1000\n",
      "10854/10854 [==============================] - 10s 933us/step - loss: 0.5684 - acc: 0.5859 - val_loss: 5.1262 - val_acc: 0.1153\n",
      "Epoch 114/1000\n",
      "10854/10854 [==============================] - 10s 958us/step - loss: 0.5656 - acc: 0.5871 - val_loss: 6.9421 - val_acc: 0.1153\n",
      "Epoch 115/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.5658 - acc: 0.5774 - val_loss: 6.5365 - val_acc: 0.1175\n",
      "Epoch 116/1000\n",
      "10854/10854 [==============================] - 14s 1ms/step - loss: 0.5649 - acc: 0.5985 - val_loss: 6.9434 - val_acc: 0.1139\n",
      "Epoch 117/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.5662 - acc: 0.5879 - val_loss: 6.3559 - val_acc: 0.1131\n",
      "Epoch 118/1000\n",
      "10854/10854 [==============================] - 13s 1ms/step - loss: 0.5659 - acc: 0.5874 - val_loss: 6.3396 - val_acc: 0.1131\n",
      "Epoch 119/1000\n",
      " 3552/10854 [========>.....................] - ETA: 8s - loss: 0.5620 - acc: 0.5859"
     ]
    ***REMOVED***,
    ***REMOVED***
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-27f03d29072b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    ***REMOVED***
   ],
   "source": [
    "# create the model\n",
    "embedding_vector_length = 32\n",
    "top_words = 10000\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=max_wiki_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(500))\n",
    "model.add(Dense(250))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=48)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 107,
   "metadata": ***REMOVED***
    "scrolled": true
   ***REMOVED***,
   "outputs": [
    ***REMOVED***
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397 2714\n"
     ]
    ***REMOVED***
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "correct = 0\n",
    "for real, trained in zip(y_pred, y_test):\n",
    "    real_val = (real < 0.5)[0]\n",
    "    trained_val = trained == 1.0\n",
    "    if real_val == trained_val:\n",
    "        correct += 1\n",
    "print(correct, len(y_pred))"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 108,
   "metadata": ***REMOVED******REMOVED***,
   "outputs": [
    ***REMOVED***
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.68%\n"
     ]
    ***REMOVED***
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 80,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "model.save(\"generated_data/complexity_classifier.h5\")"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": null,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": []
  ***REMOVED***
 ],
 "metadata": ***REMOVED***
  "kernelspec": ***REMOVED***
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  ***REMOVED***,
  "language_info": ***REMOVED***
   "codemirror_mode": ***REMOVED***
    "name": "ipython",
    "version": 3
   ***REMOVED***,
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  ***REMOVED***
 ***REMOVED***,
 "nbformat": 4,
 "nbformat_minor": 2
***REMOVED***
