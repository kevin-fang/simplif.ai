***REMOVED***
 "cells": [
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 148,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 149,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "simple_words = []\n",
    "with open('generated_data/simple_words.txt') as f:\n",
    "    for line in f:\n",
    "        simple_words.append(line.strip())\n",
    "        \n",
    "complex_words = []\n",
    "with open('generated_data/complex_words.txt') as f:\n",
    "    for line in f:\n",
    "        complex_words.append(line.strip())"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 150,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "num_words_keep = 10000"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 151,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "word_occurrences = ***REMOVED******REMOVED***\n",
    "for word in simple_words:\n",
    "    if word in word_occurrences:\n",
    "        word_occurrences[word] += 1\n",
    "    else:\n",
    "        word_occurrences[word] = 1\n",
    "\n",
    "for word in complex_words:\n",
    "    if word in word_occurrences:\n",
    "        word_occurrences[word] += 1\n",
    "    else:\n",
    "        word_occurrences[word] = 1"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 152,
   "metadata": ***REMOVED******REMOVED***,
   "outputs": [
    ***REMOVED***
     "data": ***REMOVED***
      "text/plain": [
       "19378"
      ]
     ***REMOVED***,
     "execution_count": 152,
     "metadata": ***REMOVED******REMOVED***,
     "output_type": "execute_result"
    ***REMOVED***
   ],
   "source": [
    "len(word_occurrences)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 153,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in word_occurrences:\n",
    "    words.append((word, word_occurrences[word]))\n",
    "\n",
    "words = sorted(words, key=lambda x: x[1], reverse=True)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 154,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "mappings = []\n",
    "for i, word in enumerate(words):\n",
    "    mappings.append((i, word[0]))"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 155,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "accepted = mappings[:num_words_keep]"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 156,
   "metadata": ***REMOVED***
    "scrolled": true
   ***REMOVED***,
   "outputs": [
    ***REMOVED***
     "data": ***REMOVED***
      "text/plain": [
       "10000"
      ]
     ***REMOVED***,
     "execution_count": 156,
     "metadata": ***REMOVED******REMOVED***,
     "output_type": "execute_result"
    ***REMOVED***
   ],
   "source": [
    "len(accepted)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 157,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "reverse_dict = ***REMOVED******REMOVED***\n",
    "forward_dict = ***REMOVED******REMOVED***\n",
    "for item in accepted:\n",
    "    reverse_dict[item[1]] = item[0]\n",
    "    forward_dict[item[0]] = item[1]"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 158,
   "metadata": ***REMOVED***
    "collapsed": true,
    "scrolled": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('generated_data/word_to_num.pkl', 'wb') as fp:\n",
    "    pickle.dump(reverse_dict, fp)\n",
    "    \n",
    "with open('generated_data/num_to_word.pkl', 'wb') as fp:\n",
    "    pickle.dump(forward_dict, fp)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 159,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "with open('generated_data/simple_sentences.txt') as f:\n",
    "    simple_sentences = f.read().split(\"||\")\n",
    "    \n",
    "with open('generated_data/complex_sentences.txt') as f:\n",
    "    complex_sentences = f.read().split(\"||\")"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 160,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "simple_sentence_split = []\n",
    "for i, sentence in enumerate(simple_sentences):\n",
    "    simple_sentence_split.extend(simple_sentences[i].split('.'))\n",
    "    \n",
    "complex_sentence_split = []\n",
    "for i, sentence in enumerate(complex_sentences):\n",
    "    complex_sentence_split.extend(complex_sentences[i].split('.'))"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 161,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "simple_sentences_encoded = []\n",
    "\n",
    "for i, sentence in enumerate(simple_sentence_split):\n",
    "    tmp_encoded = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in reverse_dict:\n",
    "            tmp_encoded.append(reverse_dict[word])\n",
    "    if len(tmp_encoded) > 0:\n",
    "        simple_sentences_encoded.append(tmp_encoded)\n",
    "        \n",
    "complex_sentences_encoded = []\n",
    "\n",
    "for i, sentence in enumerate(complex_sentence_split):\n",
    "    tmp_encoded = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in reverse_dict:\n",
    "            tmp_encoded.append(reverse_dict[word])\n",
    "    if len(tmp_encoded) > 0:\n",
    "        complex_sentences_encoded.append(tmp_encoded)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 162,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "simple_array = np.array(simple_sentences_encoded)\n",
    "np.save(\"generated_data/simple.npy\", simple_array)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 163,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "complex_array = np.array(simple_sentences_encoded)\n",
    "np.save(\"generated_data/complex.npy\", complex_array)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": null,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": []
  ***REMOVED***
 ],
 "metadata": ***REMOVED***
  "kernelspec": ***REMOVED***
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  ***REMOVED***,
  "language_info": ***REMOVED***
   "codemirror_mode": ***REMOVED***
    "name": "ipython",
    "version": 3
   ***REMOVED***,
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  ***REMOVED***
 ***REMOVED***,
 "nbformat": 4,
 "nbformat_minor": 2
***REMOVED***
