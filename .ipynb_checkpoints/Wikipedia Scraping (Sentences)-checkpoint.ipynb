***REMOVED***
 "cells": [
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 40,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import re\n",
    "\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 41,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('articles.json') as f:\n",
    "    data = json.load(f)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 42,
   "metadata": ***REMOVED***
    "scrolled": true
   ***REMOVED***,
   "outputs": [
    ***REMOVED***
     "data": ***REMOVED***
      "text/plain": [
       "['Donald_Trump',\n",
       " 'United_States',\n",
       " 'Bitcoin',\n",
       " 'Queen_Victoria',\n",
       " 'Elon_Musk',\n",
       " 'Facebook',\n",
       " 'Barack_Obama',\n",
       " 'YouTube',\n",
       " 'Aristotle',\n",
       " 'Statistics',\n",
       " 'Chemistry',\n",
       " 'Monkey',\n",
       " 'Chess',\n",
       " 'Python_(programming_language)',\n",
       " 'Comedy',\n",
       " 'Trial',\n",
       " 'Executive_(government)',\n",
       " 'State',\n",
       " 'President_of_the_United_States',\n",
       " 'George_H._W._Bush',\n",
       " 'Politician',\n",
       " 'Head_of_government',\n",
       " 'Leo_Varadkar',\n",
       " 'President_of_Ireland',\n",
       " 'Veto',\n",
       " 'China',\n",
       " 'Confucianism',\n",
       " 'Zhou_Dynasty',\n",
       " 'Metropolitan_area',\n",
       " 'Urban_area',\n",
       " 'Word',\n",
       " 'Religion',\n",
       " 'Spirituality',\n",
       " 'Sarah_Bernhardt',\n",
       " 'Christopher_Columbus',\n",
       " 'Yuri_Gagarin',\n",
       " 'Archimedes',\n",
       " 'Nicolaus_Copernicus',\n",
       " 'Marie_Curie',\n",
       " 'Galileo_Galilei',\n",
       " 'Karl_Marx',\n",
       " 'Friedrich_Nietzsche',\n",
       " 'Alexander_the_Great',\n",
       " 'Augustus',\n",
       " 'Napoleon',\n",
       " 'Gautama_Buddha',\n",
       " 'Jesus',\n",
       " 'Knowledge',\n",
       " 'God',\n",
       " 'Soul',\n",
       " 'Judaism',\n",
       " 'Family',\n",
       " 'Politics',\n",
       " 'Money',\n",
       " 'International_Red_Cross_and_Red_Crescent_Movement',\n",
       " 'United_Nations',\n",
       " 'Military',\n",
       " 'War',\n",
       " 'Writing',\n",
       " 'Literature',\n",
       " 'Astronomy',\n",
       " 'Galaxy',\n",
       " 'Moon',\n",
       " 'Planet',\n",
       " 'Biology',\n",
       " 'DNA',\n",
       " 'Metabolism',\n",
       " 'Evolution',\n",
       " 'Anatomy',\n",
       " 'Cell',\n",
       " 'Cancer',\n",
       " 'Malaria',\n",
       " 'Health',\n",
       " 'Organism',\n",
       " 'Insect',\n",
       " 'Bird',\n",
       " 'Mammal',\n",
       " 'Bacteria',\n",
       " 'Fungus',\n",
       " 'Chemistry',\n",
       " 'Chemical_element',\n",
       " 'Climate',\n",
       " 'Weather',\n",
       " 'Physics',\n",
       " 'Milk',\n",
       " 'Water',\n",
       " 'Human_rights',\n",
       " 'Art',\n",
       " 'Social_capital',\n",
       " 'Parasitism',\n",
       " 'Wikipedia',\n",
       " 'Document',\n",
       " 'Book',\n",
       " 'Composer',\n",
       " 'Classical_music',\n",
       " 'Serenade',\n",
       " 'Computer',\n",
       " 'President',\n",
       " 'Business',\n",
       " 'Law',\n",
       " 'Government',\n",
       " 'Prison',\n",
       " 'Medicine',\n",
       " 'Disease',\n",
       " 'Clothing',\n",
       " 'Japan',\n",
       " 'Middle_Ages',\n",
       " 'Animal',\n",
       " 'Fiction',\n",
       " 'Library',\n",
       " 'Game',\n",
       " 'Video_game',\n",
       " 'University_of_Cambridge',\n",
       " 'History']"
      ]
     ***REMOVED***,
     "execution_count": 42,
     "metadata": ***REMOVED******REMOVED***,
     "output_type": "execute_result"
    ***REMOVED***
   ],
   "source": [
    "articles = data['articles']\n",
    "articles"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 43,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "def save_sections(sections, lst, level=0):\n",
    "        for s in sections:\n",
    "            skip = [\"References\", \"Sources\", \"Further reading\", \"External links\", \"See also\", \"Other websites\"]\n",
    "            if not s.title in skip:\n",
    "                lst.append(s.text.strip())\n",
    "                save_sections(s.sections, lst, level + 1)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 44,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "def get_simplified_page(wiki):\n",
    "    return wiki.langlinks['simple']"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 45,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 46,
   "metadata": ***REMOVED***
    "scrolled": true
   ***REMOVED***,
   "outputs": [
    ***REMOVED***
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Donald_Trump\n",
      "Finished: United_States\n",
      "Finished: Bitcoin\n",
      "Finished: Queen_Victoria\n",
      "Finished: Elon_Musk\n",
      "Finished: Facebook\n",
      "Finished: Barack_Obama\n",
      "Finished: YouTube\n",
      "Finished: Aristotle\n",
      "Finished: Statistics\n",
      "Finished: Chemistry\n",
      "Finished: Monkey\n",
      "Finished: Chess\n",
      "Finished: Python_(programming_language)\n",
      "Finished: Comedy\n",
      "Finished: Trial\n",
      "Finished: Executive_(government)\n",
      "Finished: State\n",
      "Finished: President_of_the_United_States\n",
      "Finished: George_H._W._Bush\n",
      "Finished: Politician\n",
      "Finished: Head_of_government\n",
      "Finished: Leo_Varadkar\n",
      "Finished: President_of_Ireland\n",
      "Finished: Veto\n",
      "Finished: China\n",
      "Finished: Confucianism\n",
      "Finished: Zhou_Dynasty\n",
      "Finished: Metropolitan_area\n",
      "Finished: Urban_area\n",
      "Finished: Word\n",
      "Finished: Religion\n",
      "Finished: Spirituality\n",
      "Finished: Sarah_Bernhardt\n",
      "Finished: Christopher_Columbus\n",
      "Finished: Yuri_Gagarin\n",
      "Finished: Archimedes\n",
      "Finished: Nicolaus_Copernicus\n",
      "Finished: Marie_Curie\n",
      "Finished: Galileo_Galilei\n",
      "Finished: Karl_Marx\n",
      "Finished: Friedrich_Nietzsche\n",
      "Finished: Alexander_the_Great\n",
      "Finished: Augustus\n",
      "Finished: Napoleon\n",
      "Finished: Gautama_Buddha\n",
      "Finished: Jesus\n",
      "Finished: Knowledge\n",
      "Finished: God\n",
      "Finished: Soul\n",
      "Finished: Judaism\n",
      "Finished: Family\n",
      "Finished: Politics\n",
      "Finished: Money\n",
      "Finished: International_Red_Cross_and_Red_Crescent_Movement\n",
      "Finished: United_Nations\n",
      "Finished: Military\n",
      "Finished: War\n",
      "Finished: Writing\n",
      "Finished: Literature\n",
      "Finished: Astronomy\n",
      "Finished: Galaxy\n",
      "Finished: Moon\n",
      "Finished: Planet\n",
      "Finished: Biology\n",
      "Finished: DNA\n",
      "Finished: Metabolism\n",
      "Finished: Evolution\n",
      "Finished: Anatomy\n",
      "Finished: Cell\n",
      "Finished: Cancer\n",
      "Finished: Malaria\n",
      "Finished: Health\n",
      "Finished: Organism\n",
      "Finished: Insect\n",
      "Finished: Bird\n",
      "Finished: Mammal\n",
      "Finished: Bacteria\n",
      "Finished: Fungus\n",
      "Finished: Chemistry\n",
      "Finished: Chemical_element\n",
      "Finished: Climate\n",
      "Finished: Weather\n",
      "Finished: Physics\n",
      "Finished: Milk\n",
      "Finished: Water\n",
      "Finished: Human_rights\n",
      "Finished: Art\n",
      "Finished: Social_capital\n",
      "Finished: Parasitism\n",
      "Finished: Wikipedia\n",
      "Finished: Document\n",
      "Finished: Book\n",
      "Finished: Composer\n",
      "Finished: Classical_music\n",
      "Finished: Serenade\n",
      "Finished: Computer\n",
      "Finished: President\n",
      "Finished: Business\n",
      "Finished: Law\n",
      "Finished: Government\n",
      "Finished: Prison\n",
      "Finished: Medicine\n",
      "Finished: Disease\n",
      "Finished: Clothing\n",
      "Finished: Japan\n",
      "Finished: Middle_Ages\n",
      "Finished: Animal\n",
      "Finished: Fiction\n",
      "Finished: Library\n",
      "Finished: Game\n",
      "Finished: Video_game\n",
      "Finished: University_of_Cambridge\n",
      "Finished: History\n"
     ]
    ***REMOVED***
   ],
   "source": [
    "all_complex = []\n",
    "all_simple = []\n",
    "for article in articles:\n",
    "    \n",
    "    # scrape wikipedia page\n",
    "    page = wiki.page(article)\n",
    "    complex_sections = []\n",
    "    save_sections(page.sections, complex_sections)\n",
    "    \n",
    "    simple_sections = []\n",
    "    save_sections(get_simplified_page(page).sections, simple_sections)\n",
    "    \n",
    "    def process_sentences(sections):\n",
    "        sections = \". \".join(sections) \\\n",
    "            .replace('\\n', ' ')\n",
    "                    \n",
    "        remove_re = r'[!@#$%^&*()<>\"***REMOVED******REMOVED***|,+0-9~;`]'\n",
    "        sentences = re.sub(remove_re, '', sections)\n",
    "        sentences = sentences.split(' ')\n",
    "        \n",
    "        to_filter = ['', ',', '', 'U', 'S', 's', \"-Y\"]\n",
    "        sentences = filter(lambda x: x not in to_filter, sentences)\n",
    "        sentences = filter(lemmatizer.lemmatize, sentences)\n",
    "        sentences = map(lambda x: x.strip(), sentences)\n",
    "        sentences = \" \".join(list(sentences)).split(\". \")\n",
    "        sentences = filter(lambda x: x not in to_filter, sentences)\n",
    "        return list(sentences)\n",
    "    \n",
    "    complex_sentences = process_sentences(complex_sections)\n",
    "    #print(complex_sentences)\n",
    "\n",
    "    simple_sentences = process_sentences(simple_sections)\n",
    "    \n",
    "    all_complex.extend(complex_sentences[:len(simple_sentences)])\n",
    "    all_simple.extend(simple_sentences)\n",
    "#    print(complex_sentences)\n",
    "    print(\"Finished: ***REMOVED******REMOVED***\".format(article))"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 47,
   "metadata": ***REMOVED******REMOVED***,
   "outputs": [
    ***REMOVED***
     "data": ***REMOVED***
      "text/plain": [
       "6509"
      ]
     ***REMOVED***,
     "execution_count": 47,
     "metadata": ***REMOVED******REMOVED***,
     "output_type": "execute_result"
    ***REMOVED***
   ],
   "source": [
    "len(all_complex)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 48,
   "metadata": ***REMOVED***
    "scrolled": true
   ***REMOVED***,
   "outputs": [
    ***REMOVED***
     "data": ***REMOVED***
      "text/plain": [
       "6567"
      ]
     ***REMOVED***,
     "execution_count": 48,
     "metadata": ***REMOVED******REMOVED***,
     "output_type": "execute_result"
    ***REMOVED***
   ],
   "source": [
    "len(all_simple)"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 50,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": [
    "with open('generated_data/complex_sentences.txt', 'w') as file:\n",
    "    for i in all_complex[:len(all_simple)]:\n",
    "        file.write(i.lower() + '\\n')\n",
    "with open('generated_data/simple_sentences.txt', 'w') as file:\n",
    "    for i in all_simple:\n",
    "        file.write(i.lower() + '\\n')"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": 52,
   "metadata": ***REMOVED******REMOVED***,
   "outputs": [],
   "source": [
    "with open('generated_data/all_sentences.csv', 'w') as csv:\n",
    "    for i in all_complex[:len(all_simple)]:\n",
    "        csv.write(\"***REMOVED******REMOVED***,***REMOVED******REMOVED***\".format(i.lower(), \"complex\\n\"))\n",
    "    for i in all_simple:\n",
    "        csv.write(\"***REMOVED******REMOVED***,***REMOVED******REMOVED***\".format(i.lower(), \"simple\\n\"))"
   ]
  ***REMOVED***,
  ***REMOVED***
   "cell_type": "code",
   "execution_count": null,
   "metadata": ***REMOVED***
    "collapsed": true
   ***REMOVED***,
   "outputs": [],
   "source": []
  ***REMOVED***
 ],
 "metadata": ***REMOVED***
  "kernelspec": ***REMOVED***
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  ***REMOVED***,
  "language_info": ***REMOVED***
   "codemirror_mode": ***REMOVED***
    "name": "ipython",
    "version": 3
   ***REMOVED***,
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  ***REMOVED***
 ***REMOVED***,
 "nbformat": 4,
 "nbformat_minor": 2
***REMOVED***
